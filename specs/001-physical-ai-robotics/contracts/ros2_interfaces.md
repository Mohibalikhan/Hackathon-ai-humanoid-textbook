# ROS 2 Interfaces for Physical AI & Humanoid Robotics

This document outlines the key ROS 2 interfaces that will be used for communication between different components in the practical examples and discussions within the book. These interfaces define the structure of messages, services, and actions for robust inter-node communication.

## 1. Topics

### 1.1 Robot Command Topics
*   **`/robot/cmd_vel` (geometry_msgs/Twist)**
    *   **Purpose**: To send linear and angular velocity commands to the robot's base for navigation.
    *   **Fields**:
        *   `linear.x`: Forward velocity (m/s).
        *   `angular.z`: Rotational velocity (rad/s).

*   **`/robot/joint_states` (sensor_msgs/JointState)**
    *   **Purpose**: To publish the current positions, velocities, and efforts of the robot's joints.
    *   **Fields**:
        *   `name[]`: Array of joint names.
        *   `position[]`: Array of joint positions (rad).
        *   `velocity[]`: Array of joint velocities (rad/s).
        *   `effort[]`: Array of joint efforts (Nm).

### 1.2 Sensor Data Topics
*   **`/camera/image_raw` (sensor_msgs/Image)**
    *   **Purpose**: To publish raw image data from the robot's camera.
    *   **Fields**:
        *   `header`: Timestamp and frame ID.
        *   `height`, `width`: Image dimensions.
        *   `encoding`: Image pixel format (e.g., `rgb8`, `mono8`).
        *   `data`: Raw image pixel data.

*   **`/imu/data` (sensor_msgs/Imu)**
    *   **Purpose**: To publish IMU sensor data (angular velocity, linear acceleration, orientation).
    *   **Fields**:
        *   `header`: Timestamp and frame ID.
        *   `orientation`: Quaternion representing orientation.
        *   `angular_velocity`: Vector representing angular velocity (rad/s).
        *   `linear_acceleration`: Vector representing linear acceleration (m/sÂ²).

### 1.3 Vision-Language-Action (VLA) Output Topics
*   **`/vla/cognitive_plan` (std_msgs/String)**
    *   **Purpose**: To publish the high-level cognitive plan generated by the LLM.
    *   **Fields**:
        *   `data`: String containing the cognitive plan (e.g., "Pick up the red block from the table").

*   **`/vla/action_sequence` (std_msgs/String)**
    *   **Purpose**: To publish a sequence of discrete robot actions derived from the cognitive plan.
    *   **Fields**:
        *   `data`: JSON string representing a sequence of actions (e.g., `{"actions": [{"type": "move", "target": "block"}, {"type": "grasp"}]}`).

## 2. Services

### 2.1 Robot Control Services
*   **`/robot/set_gripper_state` (custom_interfaces/srv/SetGripperState)**
    *   **Purpose**: To control the opening and closing of the robot's gripper.
    *   **Request**:
        *   `state`: Boolean (true for open, false for close).
    *   **Response**:
        *   `success`: Boolean indicating if the operation was successful.

### 2.2 Environment Interaction Services
*   **`/sim/spawn_object` (gazebo_msgs/srv/SpawnEntity)**
    *   **Purpose**: To spawn new objects into the Gazebo simulation environment.
    *   **Request**:
        *   `name`: Name of the entity.
        *   `xml`: SDF/URDF XML description of the entity.
        *   `initial_pose`: Initial pose of the entity.
    *   **Response**:
        *   `success`: Boolean indicating if the operation was successful.

## 3. Actions

### 3.1 Navigation Action
*   **`/robot/navigate_to_pose` (nav2_msgs/action/NavigateToPose)**
    *   **Purpose**: To command the robot to navigate to a specific target pose in the environment.
    *   **Goal**:
        *   `pose`: Target pose (geometry_msgs/PoseStamped).
    *   **Result**:
        *   `success`: Boolean indicating if navigation was successful.
    *   **Feedback**:
        *   `current_pose`: Current robot pose.
        *   `distance_remaining`: Distance to target.

### 3.2 Manipulation Action
*   **`/robot/manipulate_object` (custom_interfaces/action/ManipulateObject)**
    *   **Purpose**: To perform a sequence of manipulation tasks, such as picking or placing objects.
    *   **Goal**:
        *   `object_id`: Identifier of the object to manipulate.
        *   `target_pose`: Optional target pose for placement.
        *   `action_type`: Enum (PICK, PLACE, PUSH).
    *   **Result**:
        *   `success`: Boolean.
    *   **Feedback**:
        *   `progress`: Percentage complete.
